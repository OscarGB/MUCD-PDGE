{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdvdi2JTAX9g",
        "outputId": "fa3a276a-23d2-45f1-dce7-1d15dfdcf7aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!lscpu\n",
        "!free -h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2200.000\n",
            "BogoMIPS:            4400.00\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        547M         10G        964K        2.0G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ZaPmhpAm5F",
        "outputId": "edf321eb-6158-43a7-cb5e-3acdcebd6eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Fri Oct 30 23:02:48 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2cc-qskApEE",
        "outputId": "69bb2b6e-fd6c-475f-9ae3-5f42d5671c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd\n",
        "!ls -la\n",
        "!ls /"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 30 22:58 ..\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 .config\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 sample_data\n",
            "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrXlaYidAzVq",
        "outputId": "6bc677fe-3606-44df-f17e-7e2ea10bdbcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/\n",
        "%ls\n",
        "!make\n",
        "!./deviceQuery"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/samples/1_Utilities/deviceQuery\n",
            "deviceQuery.cpp  Makefile  NsightEclipse.xml  readme.txt\n",
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n",
            "/usr/local/cuda-10.1/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_37,code=sm_37 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_52,code=sm_52 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o \n",
            "mkdir -p ../../bin/x86_64/linux/release\n",
            "cp deviceQuery ../../bin/x86_64/linux/release\n",
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          10.1 / 10.1\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 1\n",
            "Result = PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSIZw4TeGbDE",
        "outputId": "962e2066-d913-403d-e208-a60bdd3139e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ~\n",
        "!ls -la\n",
        "\n",
        "!mkdir pr2\n",
        "%cd pr2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "total 60\n",
            "drwx------ 1 root root 4096 Oct 30 22:59 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 30 22:58 ..\n",
            "-rw-r--r-- 1 root root 3106 Apr  9  2018 .bashrc\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:59 .cache\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:57 .config\n",
            "drwxr-xr-x 3 root root 4096 Oct 28 16:30 .gsutil\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:57 .ipython\n",
            "drwx------ 2 root root 4096 Oct 28 16:57 .jupyter\n",
            "drwxr-xr-x 2 root root 4096 Oct 30 22:59 .keras\n",
            "drwx------ 1 root root 4096 Oct 28 16:57 .local\n",
            "drwxr-xr-x 4 root root 4096 Oct 28 16:57 .npm\n",
            "-rw-r--r-- 1 root root  148 Aug 17  2015 .profile\n",
            "/root/pr2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnQvqW6wAvrI",
        "outputId": "0149e2c9-8253-4902-9567-cfcd3448a16a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Oct 30 23:02 .\n",
            "drwx------ 1 root root 4096 Oct 30 23:02 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXhQYqiR1jk",
        "outputId": "ba47d255-8a57-488b-b227-f7a31ec3e142",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma0.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "\n",
        "void add(int n, float *x, float *y) {\n",
        "\n",
        "    for (int i = 0; i < n; i++){\n",
        "        y[i] = x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    float *x = new float[N];\n",
        "    float *y = new float[N]; \n",
        "    \n",
        "    for (int i =0; i < N; i++ ){\n",
        "        x[i] = 1.0f;\n",
        "        y[i] = 2.0f;\n",
        "    }\n",
        "    add(N, x, y);\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "   \n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError,fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    delete [] x;\n",
        "    delete [] y;\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing suma0.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXRWb-MbMNnP",
        "outputId": "56bc3298-0b52-426c-df19-23746dd882e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma1.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "    \n",
        "    for (int i =0; i < n; i++){\n",
        "        y[i] = x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    float *x; // = new float[N];\n",
        "    float *y; // = new float[N]; \n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        x[i] = 1.0f;\n",
        "        y[i] = 2.0f;\n",
        "    }\n",
        "    add<<<1,1>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing suma1.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXsDKy0oMjJH",
        "outputId": "2dc7d47d-2a6e-4411-8391-555904dbbba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma2.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "\n",
        "    for (int i = 0; i < n; i++){\n",
        "        y[i] = x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    float *x; // = new float[N];\n",
        "    float *y; // = new float[N]; \n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        x[i]= 1.0f;\n",
        "        y[i]= 2.0f;\n",
        "    }\n",
        "    add<<<1,256>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError,fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "    std::cout << \"Número de errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing suma2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzO5gj0M-A-",
        "outputId": "5f6871ab-ed30-41b4-bac6-1d9fc165aedf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma_vectores.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "\n",
        "    int i = THREADS_PER_BLOCK * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < n){\n",
        "        y[i] += x[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    int N_blocks = 1 + (N-1)/THREADS_PER_BLOCK; // ceiling(N/THREADS_PER_BLOCK)\n",
        "    float *x; // = new float[N];\n",
        "    float *y; // = new float[N]; \n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        x[i]= 1.0f;\n",
        "        y[i]= 2.0f;\n",
        "    }\n",
        "    add<<<N_blocks,THREADS_PER_BLOCK>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError,fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "    std::cout << \"Número de errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxGQb7YfRNdp",
        "outputId": "1511d26f-ba2f-41da-d33e-0c6e23daebe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o suma_vectores suma_vectores.cu\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suma0.cu  suma1.cu  suma2.cu  suma_vectores  suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYe0BecYSVO2",
        "outputId": "d9551501-e592-49c8-a5fb-9813a7a50c37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./suma_vectores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==223== NVPROF is profiling process 223, command: ./suma_vectores\n",
            "Suma de 1048576 elementos\n",
            "Número de errores: 0\n",
            "Max error: 0\n",
            "==223== Profiling application: ./suma_vectores\n",
            "==223== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.7774ms         1  2.7774ms  2.7774ms  2.7774ms  add(int, float*, float*)\n",
            "      API calls:   98.69%  311.34ms         2  155.67ms  81.349us  311.26ms  cudaMallocManaged\n",
            "                    0.90%  2.8404ms         1  2.8404ms  2.8404ms  2.8404ms  cudaDeviceSynchronize\n",
            "                    0.20%  636.71us         2  318.35us  304.83us  331.87us  cudaFree\n",
            "                    0.12%  367.31us         1  367.31us  367.31us  367.31us  cuDeviceTotalMem\n",
            "                    0.05%  168.02us        97  1.7320us     139ns  68.772us  cuDeviceGetAttribute\n",
            "                    0.03%  80.993us         1  80.993us  80.993us  80.993us  cudaLaunchKernel\n",
            "                    0.01%  34.138us         1  34.138us  34.138us  34.138us  cuDeviceGetName\n",
            "                    0.00%  3.7130us         1  3.7130us  3.7130us  3.7130us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2300us         3     743ns     162ns  1.6010us  cuDeviceGetCount\n",
            "                    0.00%  1.6330us         2     816ns     349ns  1.2840us  cuDeviceGet\n",
            "                    0.00%     278ns         1     278ns     278ns     278ns  cuDeviceGetUuid\n",
            "\n",
            "==223== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     132  62.061KB  4.0000KB  932.00KB  8.000000MB  1.061536ms  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  362.8160us  Device To Host\n",
            "      10         -         -         -           -  3.089760ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9AOnrqua_-x",
        "outputId": "9dad1816-4a28-494f-b23b-ce33b9edd8bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma_matrices.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "\n",
        "__global__ void add(int n, float **x, float **y) {\n",
        "\n",
        "    int i = BLOCK_SIZE * blockIdx.x + threadIdx.x;\n",
        "    int j = BLOCK_SIZE * blockIdx.y + threadIdx.y;\n",
        "\n",
        "    if (i < n && j < n){\n",
        "        y[i][j] += x[i][j];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 10;  // N = 2^10 = 1024\n",
        "    int N_blocks = 1 + (N-1)/BLOCK_SIZE;\n",
        "    dim3 threads(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 blocks(N_blocks, N_blocks);\n",
        "    float **x;\n",
        "    float **y;\n",
        "\n",
        "    cudaMallocManaged(&x, N*sizeof(float *));\n",
        "    cudaMallocManaged(&y, N*sizeof(float *));\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "        cudaMallocManaged(x+i, N*sizeof(float));\n",
        "        cudaMallocManaged(y+i, N*sizeof(float));\n",
        "    }\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        for (int j = 0; j < N; j++){\n",
        "            x[i][j] = 1.0f;\n",
        "            y[i][j] = 2.0f;\n",
        "        }\n",
        "    }\n",
        "    add<<<blocks,threads>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "        for (int j = 0; j < N; j++){\n",
        "            maxError = fmax(maxError,fabs(y[i][j]-3.0f));\n",
        "            if (y[i][j] != 3.0) contError++;\n",
        "        } \n",
        "    }\n",
        "    std::cout << \"Suma de \" << N << \"x\" << N << \" elementos\" << std::endl;\n",
        "    std::cout << \"Número de errores: \" << contError << std::endl;\n",
        "    std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "        cudaFree(x[i]);\n",
        "        cudaFree(y[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing suma_matrices.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_BFkeDJbGA-",
        "outputId": "aa365bf3-1406-4006-f89c-1d3ddc878bb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o suma_matrices suma_matrices.cu\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "suma0.cu  suma2.cu\t suma_matrices.cu  suma_vectores.cu\n",
            "suma1.cu  suma_matrices  suma_vectores\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSrWk79DbKwu",
        "outputId": "993eed96-0976-4acd-8ef3-7df55a9b477c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./suma_matrices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==272== NVPROF is profiling process 272, command: ./suma_matrices\n",
            "Suma de 1024x1024 elementos\n",
            "Número de errores: 0\n",
            "Max error: 0\n",
            "==272== Profiling application: ./suma_matrices\n",
            "==272== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  3.5317ms         1  3.5317ms  3.5317ms  3.5317ms  add(int, float**, float**)\n",
            "      API calls:   92.85%  237.14ms      2050  115.68us  3.2120us  228.86ms  cudaMallocManaged\n",
            "                    5.51%  14.064ms      2050  6.8600us  5.3710us  173.85us  cudaFree\n",
            "                    1.39%  3.5431ms         1  3.5431ms  3.5431ms  3.5431ms  cudaDeviceSynchronize\n",
            "                    0.16%  406.21us         1  406.21us  406.21us  406.21us  cuDeviceTotalMem\n",
            "                    0.07%  166.99us        97  1.7210us     158ns  70.167us  cuDeviceGetAttribute\n",
            "                    0.02%  54.009us         1  54.009us  54.009us  54.009us  cudaLaunchKernel\n",
            "                    0.01%  33.035us         1  33.035us  33.035us  33.035us  cuDeviceGetName\n",
            "                    0.00%  4.2100us         1  4.2100us  4.2100us  4.2100us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.6040us         3     534ns     143ns  1.0530us  cuDeviceGetCount\n",
            "                    0.00%  1.1180us         2     559ns     309ns     809ns  cuDeviceGet\n",
            "                    0.00%     303ns         1     303ns     303ns     303ns  cuDeviceGetUuid\n",
            "\n",
            "==272== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     651  12.682KB  4.0000KB  308.00KB  8.062500MB  2.337472ms  Host To Device\n",
            "      75  110.08KB  4.0000KB  0.9922MB  8.062500MB  792.9600us  Device To Host\n",
            "       4         -         -         -           -  5.926368ms  Gpu page fault groups\n",
            "Total CPU Page faults: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikvJUnCb4MR",
        "outputId": "f1d136ed-d683-42c8-f445-4ae212f37ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencil_no_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        1000\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)*64\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "\tprintf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "\t  cudaGetErrorString(error), \\\n",
        "\t  __FILE__, __LINE__); \\\n",
        "\texit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\t// __shared__ int temp[/* WHAT SIZE? */];\n",
        "\t// int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\t// int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "\t// // Read input elements into shared memory\n",
        "\t// temp[lindex] = in[gindex];\n",
        "\t// if (threadIdx.x < RADIUS){\n",
        "\t// \ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t// \ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t// }\n",
        "\n",
        "\t// // Apply the stencil\n",
        "\t// int result = 0;\n",
        "\t// for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t// \tresult += temp[lindex + offset];\n",
        "\n",
        "\t// // Store the result\n",
        "\t// out[gindex-RADIUS] = result;\n",
        "\n",
        "\tint gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t\tresult += in[gindex + offset];\n",
        "\n",
        "\t// Store the result\n",
        "\tout[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "\th_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "\tif (h_out[i] != 7){\n",
        "\t  printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "\t  break;\n",
        "\t}\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "\tprintf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 1destencil_no_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aevsjMC2YD-G",
        "outputId": "ae23c5bb-3330-451d-a79d-933e98d3886c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o 1destencil_no_shared 1destencil_no_shared.cu\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencil_no_shared\t suma1.cu\tsuma_matrices.cu\n",
            "1destencil_no_shared.cu  suma2.cu\tsuma_vectores\n",
            "suma0.cu\t\t suma_matrices\tsuma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrmGWyEcLyt",
        "outputId": "8c0dc243-b115-4303-f2af-5e8605b327e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./1destencil_no_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==321== NVPROF is profiling process 321, command: ./1destencil_no_shared\n",
            "Element h_out[0] == 2001 != 7\n",
            "==321== Profiling application: ./1destencil_no_shared\n",
            "==321== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   87.73%  3.3705ms         1  3.3705ms  3.3705ms  3.3705ms  stencil_1d(int*, int*)\n",
            "                    7.98%  306.76us         1  306.76us  306.76us  306.76us  [CUDA memcpy HtoD]\n",
            "                    4.28%  164.61us         1  164.61us  164.61us  164.61us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.16%  216.18ms         2  108.09ms  124.41us  216.06ms  cudaMalloc\n",
            "                    2.43%  5.4124ms         2  2.7062ms  466.32us  4.9460ms  cudaMemcpy\n",
            "                    0.16%  350.43us         1  350.43us  350.43us  350.43us  cuDeviceTotalMem\n",
            "                    0.15%  336.60us         2  168.30us  131.71us  204.89us  cudaFree\n",
            "                    0.07%  146.79us        97  1.5130us     132ns  62.264us  cuDeviceGetAttribute\n",
            "                    0.01%  32.578us         1  32.578us  32.578us  32.578us  cudaLaunchKernel\n",
            "                    0.01%  29.099us         1  29.099us  29.099us  29.099us  cuDeviceGetName\n",
            "                    0.00%  3.5470us         1  3.5470us  3.5470us  3.5470us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.6550us         3     551ns     143ns  1.0330us  cuDeviceGetCount\n",
            "                    0.00%  1.2320us         2     616ns     257ns     975ns  cuDeviceGet\n",
            "                    0.00%     247ns         1     247ns     247ns     247ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7psX5x9VbjhW",
        "outputId": "1c73e0b2-7ac1-40c2-8422-06c9891f7bbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencilexercise.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        1000\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)*64\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "\tprintf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "\t  cudaGetErrorString(error), \\\n",
        "\t  __FILE__, __LINE__); \\\n",
        "\texit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\t__shared__ int temp[BLOCK_SIZE+2*RADIUS];\n",
        "\tint gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\tint lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "\t// Read input elements into shared memory\n",
        "\ttemp[lindex] = in[gindex];\n",
        "\tif (threadIdx.x < RADIUS){\n",
        "\t\ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t\ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t}\n",
        "\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t\tresult += temp[lindex + offset];\n",
        "\n",
        "\t// Store the result\n",
        "\tout[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "\th_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "\tif (h_out[i] != 201){\n",
        "\t  printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "\t  break;\n",
        "\t}\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "\tprintf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 1destencilexercise.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp9KyB_Kcam1",
        "outputId": "b2ee61dc-4483-4862-b1b9-c24abf53eb8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o 1destencilexercise 1destencilexercise.cu\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t suma0.cu\tsuma_matrices.cu\n",
            "1destencilexercise.cu\t suma1.cu\tsuma_vectores\n",
            "1destencil_no_shared\t suma2.cu\tsuma_vectores.cu\n",
            "1destencil_no_shared.cu  suma_matrices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gevCbnSeLxT",
        "outputId": "9824e583-f23a-4d28-f4c4-5bf9e2bdebab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./1destencilexercise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==372== NVPROF is profiling process 372, command: ./1destencilexercise\n",
            "Element h_out[0] == 768 != 7\n",
            "==372== Profiling application: ./1destencilexercise\n",
            "==372== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   85.18%  2.8662ms         1  2.8662ms  2.8662ms  2.8662ms  stencil_1d(int*, int*)\n",
            "                    9.94%  334.41us         1  334.41us  334.41us  334.41us  [CUDA memcpy HtoD]\n",
            "                    4.88%  164.26us         1  164.26us  164.26us  164.26us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.31%  212.41ms         2  106.20ms  156.26us  212.25ms  cudaMalloc\n",
            "                    2.25%  4.9140ms         2  2.4570ms  526.27us  4.3877ms  cudaMemcpy\n",
            "                    0.18%  391.60us         1  391.60us  391.60us  391.60us  cuDeviceTotalMem\n",
            "                    0.15%  324.32us         2  162.16us  120.68us  203.65us  cudaFree\n",
            "                    0.07%  147.10us        97  1.5160us     136ns  61.856us  cuDeviceGetAttribute\n",
            "                    0.02%  50.019us         1  50.019us  50.019us  50.019us  cuDeviceGetName\n",
            "                    0.02%  39.582us         1  39.582us  39.582us  39.582us  cudaLaunchKernel\n",
            "                    0.00%  3.9300us         1  3.9300us  3.9300us  3.9300us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3110us         3     770ns     140ns  1.5320us  cuDeviceGetCount\n",
            "                    0.00%  1.2860us         2     643ns     241ns  1.0450us  cuDeviceGet\n",
            "                    0.00%     242ns         1     242ns     242ns     242ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ycPFIYseTa9",
        "outputId": "4de6c8ce-0743-4a12-b452-386be604a302",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencilexercise_sync.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        1000\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)*64\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "\tprintf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "\t  cudaGetErrorString(error), \\\n",
        "\t  __FILE__, __LINE__); \\\n",
        "\texit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\t__shared__ int temp[BLOCK_SIZE+2*RADIUS];\n",
        "\tint gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\tint lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "\t// Read input elements into shared memory\n",
        "\ttemp[lindex] = in[gindex];\n",
        "\tif (threadIdx.x < RADIUS){\n",
        "\t\ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t\ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t}\n",
        "\n",
        "\t__syncthreads();\n",
        "\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t\tresult += temp[lindex + offset];\n",
        "\n",
        "\t// Store the result\n",
        "\tout[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "\th_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "\tif (h_out[i] != 201){\n",
        "\t  printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "\t  break;\n",
        "\t}\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "\tprintf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 1destencilexercise_sync.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piDN4NjVgS_B",
        "outputId": "7d02845b-12e0-46c0-8ca3-6e38815383fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o 1destencilexercise_sync 1destencilexercise_sync.cu\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t    1destencil_no_shared.cu  suma_matrices.cu\n",
            "1destencilexercise.cu\t    suma0.cu\t\t     suma_vectores\n",
            "1destencilexercise_sync     suma1.cu\t\t     suma_vectores.cu\n",
            "1destencilexercise_sync.cu  suma2.cu\n",
            "1destencil_no_shared\t    suma_matrices\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_k-II-ggVU3",
        "outputId": "8f4de121-63e9-42b8-b280-5e210b6b3e95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./1destencilexercise_sync"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==421== NVPROF is profiling process 421, command: ./1destencilexercise_sync\n",
            "Element h_out[0] == 768 != 7\n",
            "==421== Profiling application: ./1destencilexercise_sync\n",
            "==421== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   85.81%  2.8668ms         1  2.8668ms  2.8668ms  2.8668ms  stencil_1d(int*, int*)\n",
            "                    9.28%  310.06us         1  310.06us  310.06us  310.06us  [CUDA memcpy HtoD]\n",
            "                    4.91%  164.01us         1  164.01us  164.01us  164.01us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.02%  206.12ms         2  103.06ms  88.443us  206.03ms  cudaMalloc\n",
            "                    2.45%  5.2122ms         2  2.6061ms  480.51us  4.7316ms  cudaMemcpy\n",
            "                    0.22%  468.01us         2  234.01us  164.99us  303.02us  cudaFree\n",
            "                    0.20%  427.98us         1  427.98us  427.98us  427.98us  cuDeviceTotalMem\n",
            "                    0.07%  150.64us        97  1.5520us     152ns  63.588us  cuDeviceGetAttribute\n",
            "                    0.02%  35.219us         1  35.219us  35.219us  35.219us  cudaLaunchKernel\n",
            "                    0.01%  27.175us         1  27.175us  27.175us  27.175us  cuDeviceGetName\n",
            "                    0.00%  3.1060us         1  3.1060us  3.1060us  3.1060us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2790us         3     759ns     150ns  1.5570us  cuDeviceGetCount\n",
            "                    0.00%  1.1580us         2     579ns     255ns     903ns  cuDeviceGet\n",
            "                    0.00%     280ns         1     280ns     280ns     280ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb25-XWsgbh9",
        "outputId": "510e2651-c89a-4f5f-90b5-2e1aee4cd156",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 16\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\tif (col < N && fil < N) {\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += a[fil * N + k] * b[k * N + col];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\tdim3 dimGrid(1, 1);\n",
        "\tdim3 dimBlock(N, N);\n",
        "\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "  matrixMultCPU(a,b,d);\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "// imprimiendo\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[x][y] != d[x][y]){\n",
        "          printf(\"ERROR\\n\");\n",
        "          return 1;\n",
        "      }\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing matmul.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awLBEGM8GgNa",
        "outputId": "1ccd3193-6614-4606-9a51-78aec253d0b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o matmul matmul.cu\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t    1destencil_no_shared.cu  suma2.cu\n",
            "1destencilexercise.cu\t    matmul\t\t     suma_matrices\n",
            "1destencilexercise_sync     matmul.cu\t\t     suma_matrices.cu\n",
            "1destencilexercise_sync.cu  suma0.cu\t\t     suma_vectores\n",
            "1destencil_no_shared\t    suma1.cu\t\t     suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCVltgDFGl9Y",
        "outputId": "1d1ef8fc-0c67-4438-ed7b-1ad92b8ed7e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==470== NVPROF is profiling process 470, command: ./matmul\n",
            "SUCCESS\n",
            "==470== Profiling application: ./matmul\n",
            "==470== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   39.36%  3.5520us         1  3.5520us  3.5520us  3.5520us  matrixMultGPU(int*, int*, int*)\n",
            "                   38.65%  3.4880us         2  1.7440us  1.4720us  2.0160us  [CUDA memcpy HtoD]\n",
            "                   21.99%  1.9840us         1  1.9840us  1.9840us  1.9840us  [CUDA memcpy DtoH]\n",
            "      API calls:   99.64%  217.90ms         3  72.635ms  3.0220us  217.90ms  cudaMalloc\n",
            "                    0.18%  401.13us         1  401.13us  401.13us  401.13us  cuDeviceTotalMem\n",
            "                    0.08%  164.83us        97  1.6990us     157ns  68.947us  cuDeviceGetAttribute\n",
            "                    0.04%  92.027us         3  30.675us  4.2340us  78.323us  cudaFree\n",
            "                    0.02%  44.385us         3  14.795us  9.2190us  18.958us  cudaMemcpy\n",
            "                    0.02%  44.334us         1  44.334us  44.334us  44.334us  cuDeviceGetName\n",
            "                    0.01%  29.089us         1  29.089us  29.089us  29.089us  cudaLaunchKernel\n",
            "                    0.00%  3.4550us         1  3.4550us  3.4550us  3.4550us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2590us         3     753ns     166ns  1.5610us  cuDeviceGetCount\n",
            "                    0.00%  1.3490us         2     674ns     364ns     985ns  cuDeviceGet\n",
            "                    0.00%     273ns         1     273ns     273ns     273ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idQ9OdFgGngD",
        "outputId": "936daed6-926e-4a1a-d565-e2bbcd18f9fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_metrix.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 16\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\tif (col < N && fil < N) {\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += a[fil * N + k] * b[k * N + col];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(32 < N ? 32 : N, 32 < N ? 32 : N);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing matmul_metrix.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMi6VK66Js3p"
      },
      "source": [
        "!nvcc -o matmul_metrix matmul_metrix.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tOFEUmzJwnN",
        "outputId": "c4eca020-7b5b-4bc7-b59b-a8d81f0d3e2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_metrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==518== NVPROF is profiling process 518, command: ./matmul_metrix\n",
            "GFlops: 1.086403\n",
            "TPKernel: 0.007540\n",
            "Size: 16\n",
            "SUCCESS\n",
            "==518== Profiling application: ./matmul_metrix\n",
            "==518== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.83%  3.2465ms      1000  3.2460us  3.1680us  9.5040us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.11%  3.4560us         2  1.7280us  1.4720us  1.9840us  [CUDA memcpy HtoD]\n",
            "                    0.06%  1.9520us         1  1.9520us  1.9520us  1.9520us  [CUDA memcpy DtoH]\n",
            "      API calls:   95.73%  177.39ms         3  59.129ms  3.3630us  177.38ms  cudaMalloc\n",
            "                    3.84%  7.1166ms      1000  7.1160us  4.7140us  39.122us  cudaLaunchKernel\n",
            "                    0.20%  372.81us         1  372.81us  372.81us  372.81us  cuDeviceTotalMem\n",
            "                    0.09%  165.42us        97  1.7050us     140ns  67.915us  cuDeviceGetAttribute\n",
            "                    0.07%  128.73us         3  42.911us  4.3420us  112.61us  cudaFree\n",
            "                    0.03%  50.575us         3  16.858us  9.1700us  25.611us  cudaMemcpy\n",
            "                    0.02%  34.231us         1  34.231us  34.231us  34.231us  cuDeviceGetName\n",
            "                    0.01%  10.467us         2  5.2330us     721ns  9.7460us  cudaEventCreate\n",
            "                    0.01%  9.7110us         1  9.7110us  9.7110us  9.7110us  cudaEventSynchronize\n",
            "                    0.00%  8.2580us         2  4.1290us  3.9920us  4.2660us  cudaEventRecord\n",
            "                    0.00%  3.4700us         1  3.4700us  3.4700us  3.4700us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3990us         3     799ns     151ns  1.7540us  cuDeviceGetCount\n",
            "                    0.00%  1.9480us         1  1.9480us  1.9480us  1.9480us  cudaEventElapsedTime\n",
            "                    0.00%  1.3390us         2     669ns     315ns  1.0240us  cuDeviceGet\n",
            "                    0.00%     249ns         1     249ns     249ns     249ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kESx5bGWKKtt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foYB4ml-NtvZ",
        "outputId": "5f2231c4-7c32-4126-f9f7-872382268a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_metrix.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 32\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\tif (col < N && fil < N) {\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += a[fil * N + k] * b[k * N + col];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(32 < N ? 32 : N, 32 < N ? 32 : N);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_metrix.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjCt4bglNtvj"
      },
      "source": [
        "!nvcc -o matmul_metrix matmul_metrix.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIrZSGqONtvn",
        "outputId": "44968f2e-adc5-4175-ecdd-64e8f43fb2ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_metrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==566== NVPROF is profiling process 566, command: ./matmul_metrix\n",
            "GFlops: 6.067321\n",
            "TPKernel: 0.010801\n",
            "Size: 32\n",
            "SUCCESS\n",
            "==566== Profiling application: ./matmul_metrix\n",
            "==566== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.94%  9.5752ms      1000  9.5750us  9.4720us  10.849us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.04%  3.8400us         2  1.9200us  1.6960us  2.1440us  [CUDA memcpy HtoD]\n",
            "                    0.02%  2.0800us         1  2.0800us  2.0800us  2.0800us  [CUDA memcpy DtoH]\n",
            "      API calls:   94.99%  209.63ms         3  69.875ms  3.2040us  209.62ms  cudaMalloc\n",
            "                    4.15%  9.1577ms      1000  9.1570us  5.1650us  739.87us  cudaLaunchKernel\n",
            "                    0.53%  1.1757ms         1  1.1757ms  1.1757ms  1.1757ms  cudaEventSynchronize\n",
            "                    0.16%  342.52us         1  342.52us  342.52us  342.52us  cuDeviceTotalMem\n",
            "                    0.07%  144.15us        97  1.4860us     132ns  61.633us  cuDeviceGetAttribute\n",
            "                    0.06%  123.39us         3  41.130us  4.3620us  106.03us  cudaFree\n",
            "                    0.03%  57.099us         3  19.033us  11.175us  29.783us  cudaMemcpy\n",
            "                    0.01%  29.046us         1  29.046us  29.046us  29.046us  cuDeviceGetName\n",
            "                    0.01%  12.144us         2  6.0720us     625ns  11.519us  cudaEventCreate\n",
            "                    0.00%  8.5260us         2  4.2630us  4.1190us  4.4070us  cudaEventRecord\n",
            "                    0.00%  3.8460us         1  3.8460us  3.8460us  3.8460us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.3000us         1  2.3000us  2.3000us  2.3000us  cudaEventElapsedTime\n",
            "                    0.00%  2.0880us         3     696ns     169ns  1.4690us  cuDeviceGetCount\n",
            "                    0.00%  1.3780us         2     689ns     249ns  1.1290us  cuDeviceGet\n",
            "                    0.00%     280ns         1     280ns     280ns     280ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imJjhDm9PIWx",
        "outputId": "de03eb03-a76d-4428-8136-7f13c520433b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_metrix.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 64\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\tif (col < N && fil < N) {\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += a[fil * N + k] * b[k * N + col];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(32 < N ? 32 : N, 32 < N ? 32 : N);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_metrix.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xngiI-hvPIW4"
      },
      "source": [
        "!nvcc -o matmul_metrix matmul_metrix.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j4g0DaHPIW8",
        "outputId": "30dbfde8-c5e2-4619-8a6f-59fab5baefe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_metrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==614== NVPROF is profiling process 614, command: ./matmul_metrix\n",
            "GFlops: 29.313099\n",
            "TPKernel: 0.017886\n",
            "Size: 64\n",
            "SUCCESS\n",
            "==614== Profiling application: ./matmul_metrix\n",
            "==614== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.95%  16.671ms      1000  16.671us  16.544us  17.088us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.03%  5.7280us         2  2.8640us  2.6880us  3.0400us  [CUDA memcpy HtoD]\n",
            "                    0.02%  2.9770us         1  2.9770us  2.9770us  2.9770us  [CUDA memcpy DtoH]\n",
            "      API calls:   91.48%  197.21ms         3  65.737ms  2.9310us  197.20ms  cudaMalloc\n",
            "                    5.46%  11.777ms         1  11.777ms  11.777ms  11.777ms  cudaEventSynchronize\n",
            "                    2.70%  5.8206ms      1000  5.8200us  4.5280us  30.902us  cudaLaunchKernel\n",
            "                    0.18%  387.33us         1  387.33us  387.33us  387.33us  cuDeviceTotalMem\n",
            "                    0.07%  140.76us        97  1.4510us     143ns  58.826us  cuDeviceGetAttribute\n",
            "                    0.05%  108.16us         3  36.052us  4.1130us  92.817us  cudaFree\n",
            "                    0.03%  73.974us         3  24.658us  17.012us  37.669us  cudaMemcpy\n",
            "                    0.01%  30.501us         1  30.501us  30.501us  30.501us  cuDeviceGetName\n",
            "                    0.01%  10.861us         2  5.4300us     631ns  10.230us  cudaEventCreate\n",
            "                    0.00%  7.5760us         2  3.7880us  3.7710us  3.8050us  cudaEventRecord\n",
            "                    0.00%  3.0280us         1  3.0280us  3.0280us  3.0280us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.7190us         1  2.7190us  2.7190us  2.7190us  cudaEventElapsedTime\n",
            "                    0.00%  1.5670us         3     522ns     153ns     951ns  cuDeviceGetCount\n",
            "                    0.00%  1.0990us         2     549ns     270ns     829ns  cuDeviceGet\n",
            "                    0.00%     284ns         1     284ns     284ns     284ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW43FBjKPKjU"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWY6_s8vUlbC",
        "outputId": "b7ebd70c-1c4b-41a4-af11-3112a37343e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_metrix.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 128\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\tif (col < N && fil < N) {\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += a[fil * N + k] * b[k * N + col];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(32 < N ? 32 : N, 32 < N ? 32 : N);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_metrix.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhJFp-R9UlbJ"
      },
      "source": [
        "!nvcc -o matmul_metrix matmul_metrix.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "artpCb6-UlbO",
        "outputId": "54a0c333-5bba-4321-eac1-208ef24884ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_metrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==662== NVPROF is profiling process 662, command: ./matmul_metrix\n",
            "GFlops: 130.101452\n",
            "TPKernel: 0.032239\n",
            "Size: 128\n",
            "SUCCESS\n",
            "==662== Profiling application: ./matmul_metrix\n",
            "==662== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.93%  31.009ms      1000  31.009us  30.912us  31.520us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.04%  13.600us         2  6.8000us  6.6560us  6.9440us  [CUDA memcpy HtoD]\n",
            "                    0.02%  7.0080us         1  7.0080us  7.0080us  7.0080us  [CUDA memcpy DtoH]\n",
            "      API calls:   86.59%  211.89ms         3  70.632ms  3.1740us  211.89ms  cudaMalloc\n",
            "                   10.72%  26.230ms         1  26.230ms  26.230ms  26.230ms  cudaEventSynchronize\n",
            "                    2.32%  5.6890ms      1000  5.6880us  4.5350us  27.534us  cudaLaunchKernel\n",
            "                    0.14%  334.98us         1  334.98us  334.98us  334.98us  cuDeviceTotalMem\n",
            "                    0.07%  181.77us         3  60.590us  4.8610us  154.45us  cudaFree\n",
            "                    0.07%  177.39us         3  59.131us  38.571us  90.724us  cudaMemcpy\n",
            "                    0.06%  138.91us        97  1.4320us     135ns  59.436us  cuDeviceGetAttribute\n",
            "                    0.01%  25.369us         1  25.369us  25.369us  25.369us  cuDeviceGetName\n",
            "                    0.00%  8.5060us         2  4.2530us     716ns  7.7900us  cudaEventCreate\n",
            "                    0.00%  7.7760us         2  3.8880us  3.6330us  4.1430us  cudaEventRecord\n",
            "                    0.00%  4.1160us         1  4.1160us  4.1160us  4.1160us  cuDeviceGetPCIBusId\n",
            "                    0.00%  3.1530us         1  3.1530us  3.1530us  3.1530us  cudaEventElapsedTime\n",
            "                    0.00%  2.1030us         3     701ns     148ns  1.5370us  cuDeviceGetCount\n",
            "                    0.00%  1.1540us         2     577ns     330ns     824ns  cuDeviceGet\n",
            "                    0.00%     272ns         1     272ns     272ns     272ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxef46VtT59h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUjXH5g3U0AU",
        "outputId": "a806b139-b1b0-49b5-e19f-613884d67cb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_metrix.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 512\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\tif (col < N && fil < N) {\n",
        "\t\t// #pragma unroll 512\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += a[fil * N + k] * b[k * N + col];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(32 < N ? 32 : N, 32 < N ? 32 : N);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[i][j] != d[i][j]){\n",
        "\t\t\t\tprintf(\"ERROR\\n\");\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_metrix.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shlcrhXhU0Aa"
      },
      "source": [
        "!nvcc -O3 -o matmul_metrix matmul_metrix.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gOY2yhZU0Af",
        "outputId": "922a7c78-4ed1-4d4e-84a1-c8a7627e474b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_metrix"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==2492== NVPROF is profiling process 2492, command: ./matmul_metrix\n",
            "GFlops: 563.877217\n",
            "TPKernel: 0.476053\n",
            "Size: 512\n",
            "SUCCESS\n",
            "==2492== Profiling application: ./matmul_metrix\n",
            "==2492== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.95%  475.11ms      1000  475.11us  329.47us  846.80us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.04%  180.19us         2  90.094us  89.534us  90.654us  [CUDA memcpy HtoD]\n",
            "                    0.02%  81.086us         1  81.086us  81.086us  81.086us  [CUDA memcpy DtoH]\n",
            "      API calls:   69.79%  468.93ms         1  468.93ms  468.93ms  468.93ms  cudaEventSynchronize\n",
            "                   28.86%  193.88ms         3  64.628ms  8.0570us  193.77ms  cudaMalloc\n",
            "                    1.00%  6.7294ms      1000  6.7290us  5.0880us  50.578us  cudaLaunchKernel\n",
            "                    0.22%  1.4867ms         3  495.58us  254.14us  889.65us  cudaMemcpy\n",
            "                    0.05%  360.56us         1  360.56us  360.56us  360.56us  cuDeviceTotalMem\n",
            "                    0.04%  286.97us         3  95.657us  29.530us  176.43us  cudaFree\n",
            "                    0.02%  152.63us        97  1.5730us     132ns  64.208us  cuDeviceGetAttribute\n",
            "                    0.00%  30.517us         1  30.517us  30.517us  30.517us  cuDeviceGetName\n",
            "                    0.00%  9.6880us         2  4.8440us  4.6860us  5.0020us  cudaEventRecord\n",
            "                    0.00%  7.1510us         1  7.1510us  7.1510us  7.1510us  cudaEventElapsedTime\n",
            "                    0.00%  7.0270us         2  3.5130us     606ns  6.4210us  cudaEventCreate\n",
            "                    0.00%  3.9960us         1  3.9960us  3.9960us  3.9960us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9270us         3     642ns     128ns  1.3860us  cuDeviceGetCount\n",
            "                    0.00%  1.1430us         2     571ns     266ns     877ns  cuDeviceGet\n",
            "                    0.00%     295ns         1     295ns     295ns     295ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf1fJloXWt0l",
        "outputId": "56fc5497-966a-4323-f518-1f1468b68658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 16\n",
        "#define BLOCK_SIZE 32 < N ? 32 : N\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\n",
        "\t__shared__ float A[BLOCK_SIZE][N];\n",
        "\t__shared__ float B[BLOCK_SIZE][N];\n",
        "\n",
        "\tfor (int i = threadIdx.x; i < N; i+=blockDim.x){\n",
        "\t\tA[threadIdx.y][i] = a[fil*N + i];\n",
        "\t}\n",
        "\tfor (int i = threadIdx.y; i < N; i+=blockDim.y){\n",
        "\t\tB[threadIdx.x][i] = b[i*N + col];\n",
        "\t}\n",
        "\t\n",
        "\t__syncthreads();\n",
        "\n",
        "\tif (col < N && fil < N) {\n",
        "\t\t// #pragma unroll\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += A[threadIdx.y][k] * B[threadIdx.x][k];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWqe64wVwOac"
      },
      "source": [
        "!nvcc -o matmul_shared matmul_shared.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMmuZirpwX-S",
        "outputId": "8521c831-fffb-482d-953f-f853a7ad31fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1412== NVPROF is profiling process 1412, command: ./matmul_shared\n",
            "GFlops: 1.239001\n",
            "TPKernel: 0.006612\n",
            "Size: 16\n",
            "SUCCESS\n",
            "==1412== Profiling application: ./matmul_shared\n",
            "==1412== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.87%  4.3127ms      1000  4.3120us  4.2550us  13.407us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.08%  3.5200us         2  1.7600us  1.5040us  2.0160us  [CUDA memcpy HtoD]\n",
            "                    0.05%  1.9520us         1  1.9520us  1.9520us  1.9520us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.95%  221.75ms         3  73.918ms  2.8860us  221.75ms  cudaMalloc\n",
            "                    2.72%  6.2220ms      1000  6.2220us  4.7520us  28.716us  cudaLaunchKernel\n",
            "                    0.16%  360.24us         1  360.24us  360.24us  360.24us  cuDeviceTotalMem\n",
            "                    0.07%  161.76us        97  1.6670us     143ns  73.455us  cuDeviceGetAttribute\n",
            "                    0.05%  114.71us         3  38.237us  4.3950us  98.766us  cudaFree\n",
            "                    0.02%  55.502us         3  18.500us  10.439us  26.663us  cudaMemcpy\n",
            "                    0.01%  33.838us         1  33.838us  33.838us  33.838us  cuDeviceGetName\n",
            "                    0.00%  8.8970us         1  8.8970us  8.8970us  8.8970us  cudaEventSynchronize\n",
            "                    0.00%  8.7180us         2  4.3590us     665ns  8.0530us  cudaEventCreate\n",
            "                    0.00%  7.1880us         2  3.5940us  3.4190us  3.7690us  cudaEventRecord\n",
            "                    0.00%  3.3650us         1  3.3650us  3.3650us  3.3650us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0900us         1  2.0900us  2.0900us  2.0900us  cudaEventElapsedTime\n",
            "                    0.00%  2.0570us         3     685ns     173ns  1.4650us  cuDeviceGetCount\n",
            "                    0.00%  1.4260us         2     713ns     310ns  1.1160us  cuDeviceGet\n",
            "                    0.00%     284ns         1     284ns     284ns     284ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92K4Uk1Sxj-x",
        "outputId": "162b1714-0675-46ea-ffc3-bf92b6432555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 32\n",
        "#define BLOCK_SIZE 32 < N ? 32 : N\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\n",
        "\t__shared__ float A[BLOCK_SIZE][N];\n",
        "\t__shared__ float B[BLOCK_SIZE][N];\n",
        "\n",
        "\tfor (int i = threadIdx.x; i < N; i+=blockDim.x){\n",
        "\t\tA[threadIdx.y][i] = a[fil*N + i];\n",
        "\t}\n",
        "\tfor (int i = threadIdx.y; i < N; i+=blockDim.y){\n",
        "\t\tB[threadIdx.x][i] = b[i*N + col];\n",
        "\t}\n",
        "\t\n",
        "\t__syncthreads();\n",
        "\n",
        "\tif (col < N && fil < N) {\n",
        "\t\t// #pragma unroll\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += A[threadIdx.y][k] * B[threadIdx.x][k];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awjCEhjXxj--"
      },
      "source": [
        "!nvcc -o matmul_shared matmul_shared.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbAFGc1Wxj_C",
        "outputId": "7d7dd157-f6c0-4a2f-fbec-92a7828cd5aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1470== NVPROF is profiling process 1470, command: ./matmul_shared\n",
            "GFlops: 3.076632\n",
            "TPKernel: 0.021301\n",
            "Size: 32\n",
            "SUCCESS\n",
            "==1470== Profiling application: ./matmul_shared\n",
            "==1470== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.97%  20.001ms      1000  20.000us  19.840us  20.800us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.02%  3.8720us         2  1.9360us  1.6960us  2.1760us  [CUDA memcpy HtoD]\n",
            "                    0.01%  2.1120us         1  2.1120us  2.1120us  2.1120us  [CUDA memcpy DtoH]\n",
            "      API calls:   91.01%  221.57ms         3  73.857ms  3.2640us  221.56ms  cudaMalloc\n",
            "                    6.11%  14.880ms         1  14.880ms  14.880ms  14.880ms  cudaEventSynchronize\n",
            "                    2.50%  6.0944ms      1000  6.0940us  4.5860us  43.276us  cudaLaunchKernel\n",
            "                    0.15%  371.29us         1  371.29us  371.29us  371.29us  cuDeviceTotalMem\n",
            "                    0.09%  213.12us        97  2.1970us     134ns  117.53us  cuDeviceGetAttribute\n",
            "                    0.07%  161.68us         3  53.892us  4.6510us  138.42us  cudaFree\n",
            "                    0.04%  96.232us         3  32.077us  18.976us  54.144us  cudaMemcpy\n",
            "                    0.01%  31.616us         1  31.616us  31.616us  31.616us  cuDeviceGetName\n",
            "                    0.00%  8.6840us         2  4.3420us     667ns  8.0170us  cudaEventCreate\n",
            "                    0.00%  7.9550us         2  3.9770us  3.7800us  4.1750us  cudaEventRecord\n",
            "                    0.00%  4.0990us         1  4.0990us  4.0990us  4.0990us  cudaEventElapsedTime\n",
            "                    0.00%  3.2560us         1  3.2560us  3.2560us  3.2560us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.5720us         3     524ns     146ns  1.0920us  cuDeviceGetCount\n",
            "                    0.00%     868ns         2     434ns     257ns     611ns  cuDeviceGet\n",
            "                    0.00%     407ns         1     407ns     407ns     407ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFsVQgSMxkP1",
        "outputId": "ac7e060e-8661-47ed-da9d-a8a4e6bb0c1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 64\n",
        "#define BLOCK_SIZE 32 < N ? 32 : N\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\n",
        "\t__shared__ float A[BLOCK_SIZE][N];\n",
        "\t__shared__ float B[BLOCK_SIZE][N];\n",
        "\n",
        "\tfor (int i = threadIdx.x; i < N; i+=blockDim.x){\n",
        "\t\tA[threadIdx.y][i] = a[fil*N + i];\n",
        "\t}\n",
        "\tfor (int i = threadIdx.y; i < N; i+=blockDim.y){\n",
        "\t\tB[threadIdx.x][i] = b[i*N + col];\n",
        "\t}\n",
        "\t\n",
        "\t__syncthreads();\n",
        "\n",
        "\tif (col < N && fil < N) {\n",
        "\t\t// #pragma unroll\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += A[threadIdx.y][k] * B[threadIdx.x][k];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikc6bhEBxkP8"
      },
      "source": [
        "!nvcc -o matmul_shared matmul_shared.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8D3eecOxkP_",
        "outputId": "16077412-fa75-4796-aec7-ef429384d248",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1526== NVPROF is profiling process 1526, command: ./matmul_shared\n",
            "GFlops: 13.506618\n",
            "TPKernel: 0.038817\n",
            "Size: 64\n",
            "SUCCESS\n",
            "==1526== Profiling application: ./matmul_shared\n",
            "==1526== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.98%  37.563ms      1000  37.562us  37.183us  38.239us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.02%  5.8560us         2  2.9280us  2.7200us  3.1360us  [CUDA memcpy HtoD]\n",
            "                    0.01%  3.0080us         1  3.0080us  3.0080us  3.0080us  [CUDA memcpy DtoH]\n",
            "      API calls:   82.44%  184.83ms         3  61.610ms  3.1650us  184.82ms  cudaMalloc\n",
            "                   14.73%  33.016ms         1  33.016ms  33.016ms  33.016ms  cudaEventSynchronize\n",
            "                    2.46%  5.5190ms      1000  5.5190us  4.4830us  25.594us  cudaLaunchKernel\n",
            "                    0.18%  394.26us         1  394.26us  394.26us  394.26us  cuDeviceTotalMem\n",
            "                    0.07%  152.24us        97  1.5690us     135ns  64.891us  cuDeviceGetAttribute\n",
            "                    0.06%  125.01us         3  41.670us  5.3760us  105.10us  cudaFree\n",
            "                    0.04%  88.561us         3  29.520us  18.816us  44.814us  cudaMemcpy\n",
            "                    0.01%  27.680us         1  27.680us  27.680us  27.680us  cuDeviceGetName\n",
            "                    0.01%  20.771us         1  20.771us  20.771us  20.771us  cudaEventElapsedTime\n",
            "                    0.00%  7.2210us         2  3.6100us  3.4480us  3.7730us  cudaEventRecord\n",
            "                    0.00%  4.9490us         2  2.4740us     536ns  4.4130us  cudaEventCreate\n",
            "                    0.00%  2.9290us         1  2.9290us  2.9290us  2.9290us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.9840us         3     661ns     178ns  1.4290us  cuDeviceGetCount\n",
            "                    0.00%  1.1980us         2     599ns     215ns     983ns  cuDeviceGet\n",
            "                    0.00%     244ns         1     244ns     244ns     244ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqfgqdjlxkgO",
        "outputId": "aab49007-9bbd-41f9-9a5c-207fe8febae2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 128\n",
        "#define BLOCK_SIZE 32 < N ? 32 : N\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\n",
        "\t__shared__ float A[BLOCK_SIZE][N];\n",
        "\t__shared__ float B[BLOCK_SIZE][N];\n",
        "\n",
        "\tfor (int i = threadIdx.x; i < N; i+=blockDim.x){\n",
        "\t\tA[threadIdx.y][i] = a[fil*N + i];\n",
        "\t}\n",
        "\tfor (int i = threadIdx.y; i < N; i+=blockDim.y){\n",
        "\t\tB[threadIdx.x][i] = b[i*N + col];\n",
        "\t}\n",
        "\t\n",
        "\t__syncthreads();\n",
        "\n",
        "\tif (col < N && fil < N) {\n",
        "\t\t// #pragma unroll\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += A[threadIdx.y][k] * B[threadIdx.x][k];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaJ9b_KexkgT"
      },
      "source": [
        "!nvcc -O3 -o matmul_shared matmul_shared.cu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmzwgnTQxkgX",
        "outputId": "8b9586d7-7eb0-418d-f356-e593da49e993",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==2218== NVPROF is profiling process 2218, command: ./matmul_shared\n",
            "GFlops: 57.423866\n",
            "TPKernel: 0.073041\n",
            "Size: 128\n",
            "SUCCESS\n",
            "==2218== Profiling application: ./matmul_shared\n",
            "==2218== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.97%  71.811ms      1000  71.811us  71.615us  72.543us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.02%  13.344us         2  6.6720us  6.5280us  6.8160us  [CUDA memcpy HtoD]\n",
            "                    0.01%  6.9110us         1  6.9110us  6.9110us  6.9110us  [CUDA memcpy DtoH]\n",
            "      API calls:   71.55%  185.38ms         3  61.794ms  3.0520us  185.38ms  cudaMalloc\n",
            "                   25.90%  67.110ms         1  67.110ms  67.110ms  67.110ms  cudaEventSynchronize\n",
            "                    2.18%  5.6526ms      1000  5.6520us  4.4280us  34.055us  cudaLaunchKernel\n",
            "                    0.16%  407.77us         1  407.77us  407.77us  407.77us  cuDeviceTotalMem\n",
            "                    0.07%  183.82us        97  1.8950us     140ns  77.197us  cuDeviceGetAttribute\n",
            "                    0.07%  173.48us         3  57.827us  36.366us  97.791us  cudaMemcpy\n",
            "                    0.05%  141.28us         3  47.093us  6.0430us  118.95us  cudaFree\n",
            "                    0.01%  31.309us         1  31.309us  31.309us  31.309us  cuDeviceGetName\n",
            "                    0.00%  10.311us         2  5.1550us     593ns  9.7180us  cudaEventCreate\n",
            "                    0.00%  6.8330us         2  3.4160us  3.2130us  3.6200us  cudaEventRecord\n",
            "                    0.00%  3.7050us         1  3.7050us  3.7050us  3.7050us  cudaEventElapsedTime\n",
            "                    0.00%  2.9640us         1  2.9640us  2.9640us  2.9640us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8920us         3     630ns     185ns  1.3310us  cuDeviceGetCount\n",
            "                    0.00%  1.2690us         2     634ns     340ns     929ns  cuDeviceGet\n",
            "                    0.00%     269ns         1     269ns     269ns     269ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79C9EFFMxm2C",
        "outputId": "03724839-4c47-4e61-fd66-253e5f144c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile matmul_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#define N 512\n",
        "#define BLOCK_SIZE 32 < N ? 32 : N\n",
        "void matrixMultCPU(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "\tint n,m;\n",
        "\tfor (int i = 0; i < N; i++) {\n",
        "\t\tfor (int j = 0; j < N; j++) {\n",
        "\t\t\tint sum = 0;\n",
        "\t\t\tfor (int k = 0; k < N; k++) {\n",
        "\t\t\t\tm = a[i][k];\n",
        "\t\t\t\tn = b[k][j];\n",
        "\t\t\t\tsum += m * n;\n",
        "\t\t\t}\n",
        "\t\t\tc[i][j] = sum;\n",
        "\t\t}\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "__global__ void matrixMultGPU(int *a, int *b, int *c) {\n",
        "\tint k, sum = 0;\n",
        "\tint col = threadIdx.x + blockDim.x * blockIdx.x;\n",
        "\tint fil = threadIdx.y + blockDim.y * blockIdx.y;\n",
        "\n",
        "\t__shared__ float A[BLOCK_SIZE][N];\n",
        "\t__shared__ float B[BLOCK_SIZE][N];\n",
        "\n",
        "\tfor (int i = threadIdx.x; i < N; i+=blockDim.x){\n",
        "\t\tA[threadIdx.y][i] = a[fil*N + i];\n",
        "\t}\n",
        "\tfor (int i = threadIdx.y; i < N; i+=blockDim.y){\n",
        "\t\tB[threadIdx.x][i] = b[i*N + col];\n",
        "\t}\n",
        "\t\n",
        "\t__syncthreads();\n",
        "\n",
        "\tif (col < N && fil < N) {\n",
        "\t\t// #pragma unroll\n",
        "\t\tfor (k = 0; k < N; k++) {\n",
        "\t\t\tsum += A[threadIdx.y][k] * B[threadIdx.x][k];\n",
        "\t\t}\n",
        "\t\tc[fil * N + col] = sum;\n",
        "\t}\n",
        "}\n",
        "\n",
        "\n",
        "int main() {\n",
        "\tint a[N][N], b[N][N], c[N][N], d[N][N];\n",
        "\tint *dev_a, *dev_b, *dev_c;\n",
        "\tint cont,i,j;\n",
        "/* inicializando variables con datos*/\n",
        "\tfor (i = 0; i < N; i++) {\n",
        "\t\tcont = 0;\n",
        "\t\tfor (j = 0; j < N; j++) {\n",
        "\t\t\ta[i][j] = cont;\n",
        "\t\t\tb[i][j] = cont;\n",
        "\t\t\tcont++;\n",
        "\t\t}\n",
        "\t}\n",
        "\tint size = N * N * sizeof(int);\n",
        "\n",
        "\tcudaMalloc((void **) &dev_a, size);\n",
        "\tcudaMalloc((void **) &dev_b, size);\n",
        "\tcudaMalloc((void **) &dev_c, size);\n",
        "\n",
        "\tcudaMemcpy(dev_a, a, size, cudaMemcpyHostToDevice);\n",
        "\tcudaMemcpy(dev_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "\tdim3 dimGrid((N+32-1)/32, (N+32-1)/32);\n",
        "\tdim3 dimBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "\n",
        "  \t// Allocate CUDA events that we'll use for timing\n",
        "\tcudaEvent_t start;\n",
        "\tcudaEventCreate(&start);\n",
        "\tcudaEvent_t stop;\n",
        "\tcudaEventCreate(&stop);\n",
        " // Record the start event\n",
        "\tcudaEventRecord(start, NULL);\n",
        "// Repita la ejecucion del kernel 1000 veces para eliminar\n",
        "// efectos de arranque en frio\n",
        "\tint nIter = 1000;\n",
        "\tfor (int j = 0; j < nIter; j++)\n",
        "\t\tmatrixMultGPU<<<dimGrid, dimBlock>>>(dev_a, dev_b, dev_c);\n",
        "\n",
        " // Record the stop event\n",
        "\tcudaEventRecord(stop, NULL);\n",
        " // Wait for the stop event to complete\n",
        "\tcudaEventSynchronize(stop);\n",
        "\tfloat msecTotal = 0.0f;\n",
        "\tcudaEventElapsedTime(&msecTotal, start, stop);\n",
        "// Compute and print the performance\n",
        "\tfloat msecPerKernelExecution = msecTotal / nIter;\n",
        "\tdouble flopsPerMMul = 2.0 * N * N * N;\n",
        "\tdouble gigaFlops = (flopsPerMMul * 1.0e-9f) /\n",
        "\t(msecPerKernelExecution / 1000.0f);\n",
        "\n",
        "\tprintf(\"GFlops: %lf\\n\", gigaFlops);\n",
        "\tprintf(\"TPKernel: %lf\\n\", msecPerKernelExecution);\n",
        "\tprintf(\"Size: %d\\n\", N);\n",
        "\n",
        "\tmatrixMultCPU(a,b,d);\n",
        "\n",
        "\tcudaMemcpy(c, dev_c, size, cudaMemcpyDeviceToHost);\n",
        "\tcudaFree(dev_a);\n",
        "\tcudaFree(dev_b);\n",
        "\tcudaFree(dev_c);\n",
        "\n",
        "// comprobando\n",
        "\tfor (int y = 0; y < N; y++) {\n",
        "\t\tfor (int x = 0; x < N; x++) {\n",
        "\t\t\tif (c[y][x] != d[y][x]){\n",
        "\t\t\t\tprintf(\"ERROR en %d %d, %d != %d\\n\", y,x,c[y][x], d[y][x]);\n",
        "\t\t\t\treturn 1;\n",
        "\t\t\t}\n",
        "\t\t}\n",
        "\t}\n",
        "\tprintf(\"SUCCESS\\n\");\n",
        "\treturn 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting matmul_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBQM6D15xm2G",
        "outputId": "5aae0bd5-6577-4030-e214-f91caf21c8f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o matmul_shared matmul_shared.cu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ptxas error   : Entry function '_Z13matrixMultGPUPiS_S_' uses too much shared data (0x20000 bytes, 0xc000 max)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMxUxdZ7xm2I",
        "outputId": "664aac6f-c95b-470b-940d-138a0e125bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./matmul_shared"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1671== NVPROF is profiling process 1671, command: ./matmul_shared\n",
            "GFlops: 57.365288\n",
            "TPKernel: 0.073116\n",
            "Size: 128\n",
            "SUCCESS\n",
            "==1671== Profiling application: ./matmul_shared\n",
            "==1671== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   99.97%  71.819ms      1000  71.819us  71.549us  72.606us  matrixMultGPU(int*, int*, int*)\n",
            "                    0.02%  14.015us         2  7.0070us  6.7200us  7.2950us  [CUDA memcpy HtoD]\n",
            "                    0.01%  6.9760us         1  6.9760us  6.9760us  6.9760us  [CUDA memcpy DtoH]\n",
            "      API calls:   72.94%  198.63ms         3  66.209ms  3.4710us  198.62ms  cudaMalloc\n",
            "                   24.18%  65.853ms         1  65.853ms  65.853ms  65.853ms  cudaEventSynchronize\n",
            "                    2.50%  6.7984ms      1000  6.7980us  5.2010us  35.387us  cudaLaunchKernel\n",
            "                    0.13%  343.45us         1  343.45us  343.45us  343.45us  cuDeviceTotalMem\n",
            "                    0.09%  235.44us         3  78.481us  5.6650us  205.44us  cudaFree\n",
            "                    0.08%  229.41us         3  76.471us  41.707us  136.42us  cudaMemcpy\n",
            "                    0.06%  160.00us        97  1.6490us     137ns  66.561us  cuDeviceGetAttribute\n",
            "                    0.01%  32.131us         1  32.131us  32.131us  32.131us  cuDeviceGetName\n",
            "                    0.00%  9.0990us         2  4.5490us  4.3350us  4.7640us  cudaEventRecord\n",
            "                    0.00%  7.9780us         2  3.9890us     591ns  7.3870us  cudaEventCreate\n",
            "                    0.00%  5.7100us         1  5.7100us  5.7100us  5.7100us  cudaEventElapsedTime\n",
            "                    0.00%  3.4840us         1  3.4840us  3.4840us  3.4840us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2870us         3     762ns     156ns  1.4680us  cuDeviceGetCount\n",
            "                    0.00%  1.2660us         2     633ns     377ns     889ns  cuDeviceGet\n",
            "                    0.00%     303ns         1     303ns     303ns     303ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usIhKJgGxNiT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}