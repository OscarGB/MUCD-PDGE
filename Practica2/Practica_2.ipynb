{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdvdi2JTAX9g",
        "outputId": "4bfd8b81-0121-4b9f-a3e8-dfd6e7d0d8a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!lscpu\n",
        "!free -h"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Architecture:        x86_64\n",
            "CPU op-mode(s):      32-bit, 64-bit\n",
            "Byte Order:          Little Endian\n",
            "CPU(s):              2\n",
            "On-line CPU(s) list: 0,1\n",
            "Thread(s) per core:  2\n",
            "Core(s) per socket:  1\n",
            "Socket(s):           1\n",
            "NUMA node(s):        1\n",
            "Vendor ID:           GenuineIntel\n",
            "CPU family:          6\n",
            "Model:               79\n",
            "Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "Stepping:            0\n",
            "CPU MHz:             2200.000\n",
            "BogoMIPS:            4400.00\n",
            "Hypervisor vendor:   KVM\n",
            "Virtualization type: full\n",
            "L1d cache:           32K\n",
            "L1i cache:           32K\n",
            "L2 cache:            256K\n",
            "L3 cache:            56320K\n",
            "NUMA node0 CPU(s):   0,1\n",
            "Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:            12G        547M          9G        964K        2.2G         11G\n",
            "Swap:            0B          0B          0B\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2ZaPmhpAm5F",
        "outputId": "058f4ac2-f0a3-410b-cfaa-e3cb0279b675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n",
            "Thu Oct 29 22:33:18 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.32.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2cc-qskApEE",
        "outputId": "0f055352-42da-4d34-adfe-ac48724542c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pwd\n",
        "!ls -la\n",
        "!ls /"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 29 21:57 ..\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 .config\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:30 sample_data\n",
            "bin\t datalab  home\t lib64\topt   run   swift\t       tmp    var\n",
            "boot\t dev\t  lib\t media\tproc  sbin  sys\t\t       tools\n",
            "content  etc\t  lib32  mnt\troot  srv   tensorflow-1.15.2  usr\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrXlaYidAzVq",
        "outputId": "a3aaebc3-4212-48e6-9d40-086818fd84c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd /usr/local/cuda/samples/1_Utilities/deviceQuery/\n",
        "%ls\n",
        "!make\n",
        "!./deviceQuery"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda-10.1/samples/1_Utilities/deviceQuery\n",
            "\u001b[0m\u001b[01;32mdeviceQuery\u001b[0m*     deviceQuery.o  NsightEclipse.xml\n",
            "deviceQuery.cpp  Makefile       readme.txt\n",
            "make: Nothing to be done for 'all'.\n",
            "./deviceQuery Starting...\n",
            "\n",
            " CUDA Device Query (Runtime API) version (CUDART static linking)\n",
            "\n",
            "Detected 1 CUDA Capable device(s)\n",
            "\n",
            "Device 0: \"Tesla T4\"\n",
            "  CUDA Driver Version / Runtime Version          10.1 / 10.1\n",
            "  CUDA Capability Major/Minor version number:    7.5\n",
            "  Total amount of global memory:                 15080 MBytes (15812263936 bytes)\n",
            "  (40) Multiprocessors, ( 64) CUDA Cores/MP:     2560 CUDA Cores\n",
            "  GPU Max Clock rate:                            1590 MHz (1.59 GHz)\n",
            "  Memory Clock rate:                             5001 Mhz\n",
            "  Memory Bus Width:                              256-bit\n",
            "  L2 Cache Size:                                 4194304 bytes\n",
            "  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\n",
            "  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\n",
            "  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\n",
            "  Total amount of constant memory:               65536 bytes\n",
            "  Total amount of shared memory per block:       49152 bytes\n",
            "  Total number of registers available per block: 65536\n",
            "  Warp size:                                     32\n",
            "  Maximum number of threads per multiprocessor:  1024\n",
            "  Maximum number of threads per block:           1024\n",
            "  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n",
            "  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n",
            "  Maximum memory pitch:                          2147483647 bytes\n",
            "  Texture alignment:                             512 bytes\n",
            "  Concurrent copy and kernel execution:          Yes with 3 copy engine(s)\n",
            "  Run time limit on kernels:                     No\n",
            "  Integrated GPU sharing Host Memory:            No\n",
            "  Support host page-locked memory mapping:       Yes\n",
            "  Alignment requirement for Surfaces:            Yes\n",
            "  Device has ECC support:                        Enabled\n",
            "  Device supports Unified Addressing (UVA):      Yes\n",
            "  Device supports Compute Preemption:            Yes\n",
            "  Supports Cooperative Kernel Launch:            Yes\n",
            "  Supports MultiDevice Co-op Kernel Launch:      Yes\n",
            "  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 4\n",
            "  Compute Mode:\n",
            "     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\n",
            "\n",
            "deviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.1, CUDA Runtime Version = 10.1, NumDevs = 1\n",
            "Result = PASS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSIZw4TeGbDE",
        "outputId": "8d8f9be3-2a61-4c20-cfc6-726d94643c1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%cd ~\n",
        "!ls -la\n",
        "\n",
        "!mkdir pr2\n",
        "%cd pr2"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n",
            "total 68\n",
            "drwx------ 1 root root 4096 Oct 29 22:00 .\n",
            "drwxr-xr-x 1 root root 4096 Oct 29 21:57 ..\n",
            "-rw-r--r-- 1 root root 3106 Apr  9  2018 .bashrc\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:59 .cache\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:57 .config\n",
            "drwxr-xr-x 3 root root 4096 Oct 28 16:30 .gsutil\n",
            "drwxr-xr-x 1 root root 4096 Oct 28 16:57 .ipython\n",
            "drwx------ 2 root root 4096 Oct 28 16:57 .jupyter\n",
            "drwxr-xr-x 2 root root 4096 Oct 29 21:58 .keras\n",
            "drwx------ 1 root root 4096 Oct 28 16:57 .local\n",
            "drwxr-xr-x 4 root root 4096 Oct 28 16:57 .npm\n",
            "drwx------ 3 root root 4096 Oct 29 22:00 .nv\n",
            "drwxr-xr-x 2 root root 4096 Oct 29 22:29 pr2\n",
            "-rw-r--r-- 1 root root  148 Aug 17  2015 .profile\n",
            "mkdir: cannot create directory ‘pr2’: File exists\n",
            "/root/pr2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnQvqW6wAvrI",
        "outputId": "c2f57b15-cd76-4218-d3e0-7c315b1d3a9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 2592\n",
            "drwxr-xr-x 2 root root   4096 Oct 29 22:29 .\n",
            "drwx------ 1 root root   4096 Oct 29 22:00 ..\n",
            "-rwxr-xr-x 1 root root 650536 Oct 29 22:29 1destencilexercise\n",
            "-rw-r--r-- 1 root root   2044 Oct 29 22:00 1destencil_exercise.cu\n",
            "-rw-r--r-- 1 root root   1949 Oct 29 22:29 1destencilexercise.cu\n",
            "-rwxr-xr-x 1 root root 650536 Oct 29 22:18 1destencil_no_shared\n",
            "-rw-r--r-- 1 root root   2239 Oct 29 22:18 1destencil_no_shared.cu\n",
            "-rw-r--r-- 1 root root    806 Oct 29 22:00 suma0.cu\n",
            "-rw-r--r-- 1 root root    956 Oct 29 22:00 suma1.cu\n",
            "-rw-r--r-- 1 root root    953 Oct 29 22:00 suma2.cu\n",
            "-rwxr-xr-x 1 root root 651304 Oct 29 22:00 suma_matrices\n",
            "-rw-r--r-- 1 root root   1521 Oct 29 22:00 suma_matrices.cu\n",
            "-rwxr-xr-x 1 root root 651224 Oct 29 22:00 suma_vectores\n",
            "-rw-r--r-- 1 root root   1123 Oct 29 22:00 suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wXhQYqiR1jk",
        "outputId": "29b43a8c-4572-49f3-8b41-b8a21514b5d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma0.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "\n",
        "void add(int n, float *x, float *y) {\n",
        "\n",
        "    for (int i = 0; i < n; i++){\n",
        "        y[i] = x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    float *x = new float[N];\n",
        "    float *y = new float[N]; \n",
        "    \n",
        "    for (int i =0; i < N; i++ ){\n",
        "        x[i] = 1.0f;\n",
        "        y[i] = 2.0f;\n",
        "    }\n",
        "    add(N, x, y);\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "   \n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError,fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    delete [] x;\n",
        "    delete [] y;\n",
        "    return 0;\n",
        "}\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma0.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXRWb-MbMNnP",
        "outputId": "85579b35-8f6c-4832-a547-3acbbaa28070",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma1.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "    \n",
        "    for (int i =0; i < n; i++){\n",
        "        y[i] = x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    float *x; // = new float[N];\n",
        "    float *y; // = new float[N]; \n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        x[i] = 1.0f;\n",
        "        y[i] = 2.0f;\n",
        "    }\n",
        "    add<<<1,1>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"suma de \" << N << \" Elementos\" << std::endl;\n",
        "    std::cout << \"Número de Errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma1.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXsDKy0oMjJH",
        "outputId": "3ce75856-d0e1-45a1-827c-0bdd3e1f6a17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma2.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "\n",
        "    for (int i = 0; i < n; i++){\n",
        "        y[i] = x[i]+y[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    float *x; // = new float[N];\n",
        "    float *y; // = new float[N]; \n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        x[i]= 1.0f;\n",
        "        y[i]= 2.0f;\n",
        "    }\n",
        "    add<<<1,256>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError,fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "    std::cout << \"Número de errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzO5gj0M-A-",
        "outputId": "a2402335-b20a-4100-9ce9-4eb4fdb8aa04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma_vectores.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "#define THREADS_PER_BLOCK 1024\n",
        "\n",
        "__global__ void add(int n, float *x, float *y) {\n",
        "\n",
        "    int i = THREADS_PER_BLOCK * blockIdx.x + threadIdx.x;\n",
        "\n",
        "    if (i < n){\n",
        "        y[i] += x[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 20;  // N = 2^20 = 1024*1024= 1.048.576\n",
        "    int N_blocks = 1 + (N-1)/THREADS_PER_BLOCK; // ceiling(N/THREADS_PER_BLOCK)\n",
        "    float *x; // = new float[N];\n",
        "    float *y; // = new float[N]; \n",
        "    cudaMallocManaged(&x, N*sizeof(float));\n",
        "    cudaMallocManaged(&y, N*sizeof(float));\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        x[i]= 1.0f;\n",
        "        y[i]= 2.0f;\n",
        "    }\n",
        "    add<<<N_blocks,THREADS_PER_BLOCK>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "       maxError = fmax(maxError,fabs(y[i]-3.0f));\n",
        "       if (y[i] != 3.0) contError++; \n",
        "    }\n",
        "    std::cout << \"Suma de \" << N << \" elementos\" << std::endl;\n",
        "    std::cout << \"Número de errores: \" <<contError << std::endl;\n",
        "    std::cout << \"Max error: \" <<maxError << std::endl;\n",
        "\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxGQb7YfRNdp",
        "outputId": "d8f8c93a-9331-4383-fa38-037fbf5cb135",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o suma_vectores suma_vectores.cu\n",
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t1destencil_no_shared.cu  suma_matrices\n",
            "1destencil_exercise.cu\tsuma0.cu\t\t suma_matrices.cu\n",
            "1destencilexercise.cu\tsuma1.cu\t\t suma_vectores\n",
            "1destencil_no_shared\tsuma2.cu\t\t suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYe0BecYSVO2",
        "outputId": "9b9dd131-e264-40f0-89e7-88d2e806e31d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./suma_vectores"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==730== NVPROF is profiling process 730, command: ./suma_vectores\n",
            "Suma de 1048576 elementos\n",
            "Número de errores: 0\n",
            "Max error: 0\n",
            "==730== Profiling application: ./suma_vectores\n",
            "==730== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  2.7325ms         1  2.7325ms  2.7325ms  2.7325ms  add(int, float*, float*)\n",
            "      API calls:   98.19%  215.46ms         2  107.73ms  36.614us  215.42ms  cudaMallocManaged\n",
            "                    1.24%  2.7269ms         1  2.7269ms  2.7269ms  2.7269ms  cudaDeviceSynchronize\n",
            "                    0.24%  527.18us         2  263.59us  257.97us  269.22us  cudaFree\n",
            "                    0.19%  414.17us         1  414.17us  414.17us  414.17us  cuDeviceTotalMem\n",
            "                    0.08%  173.04us        97  1.7830us     145ns  81.857us  cuDeviceGetAttribute\n",
            "                    0.03%  68.736us         1  68.736us  68.736us  68.736us  cudaLaunchKernel\n",
            "                    0.02%  43.973us         1  43.973us  43.973us  43.973us  cuDeviceGetName\n",
            "                    0.00%  3.5490us         1  3.5490us  3.5490us  3.5490us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.2810us         3     760ns     158ns  1.5890us  cuDeviceGetCount\n",
            "                    0.00%  1.4620us         2     731ns     295ns  1.1670us  cuDeviceGet\n",
            "                    0.00%     310ns         1     310ns     310ns     310ns  cuDeviceGetUuid\n",
            "\n",
            "==730== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     144  56.889KB  4.0000KB  920.00KB  8.000000MB  1.056576ms  Host To Device\n",
            "      24  170.67KB  4.0000KB  0.9961MB  4.000000MB  361.8240us  Device To Host\n",
            "       9         -         -         -           -  2.814400ms  Gpu page fault groups\n",
            "Total CPU Page faults: 36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9AOnrqua_-x",
        "outputId": "92c2ebe6-de3c-4c7a-b983-659b7f7f8fba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile suma_matrices.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <math.h>\n",
        "\n",
        "#define BLOCK_SIZE 32\n",
        "\n",
        "__global__ void add(int n, float **x, float **y) {\n",
        "\n",
        "    int i = BLOCK_SIZE * blockIdx.x + threadIdx.x;\n",
        "    int j = BLOCK_SIZE * blockIdx.y + threadIdx.y;\n",
        "\n",
        "    if (i < n && j < n){\n",
        "        y[i][j] += x[i][j];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main(void) {\n",
        "    \n",
        "    int N = 1 << 10;  // N = 2^10 = 1024\n",
        "    int N_blocks = 1 + (N-1)/BLOCK_SIZE;\n",
        "    dim3 threads(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 blocks(N_blocks, N_blocks);\n",
        "    float **x;\n",
        "    float **y;\n",
        "\n",
        "    cudaMallocManaged(&x, N*sizeof(float *));\n",
        "    cudaMallocManaged(&y, N*sizeof(float *));\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "        cudaMallocManaged(x+i, N*sizeof(float));\n",
        "        cudaMallocManaged(y+i, N*sizeof(float));\n",
        "    }\n",
        "    \n",
        "    for (int i = 0; i < N; i++){\n",
        "        for (int j = 0; j < N; j++){\n",
        "            x[i][j] = 1.0f;\n",
        "            y[i][j] = 2.0f;\n",
        "        }\n",
        "    }\n",
        "    add<<<blocks,threads>>>(N, x, y);\n",
        "    cudaDeviceSynchronize();\n",
        "    float maxError = 0.0f;\n",
        "    int contError = 0;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "        for (int j = 0; j < N; j++){\n",
        "            maxError = fmax(maxError,fabs(y[i][j]-3.0f));\n",
        "            if (y[i][j] != 3.0) contError++;\n",
        "        } \n",
        "    }\n",
        "    std::cout << \"Suma de \" << N << \"x\" << N << \" elementos\" << std::endl;\n",
        "    std::cout << \"Número de errores: \" << contError << std::endl;\n",
        "    std::cout << \"Max error: \" << maxError << std::endl;\n",
        "\n",
        "    for (int i = 0; i < N; i++){\n",
        "        cudaFree(x[i]);\n",
        "        cudaFree(y[i]);\n",
        "    }\n",
        "\n",
        "    cudaFree (x);\n",
        "    cudaFree (y);\n",
        "   \n",
        "   return 0;\n",
        "}"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting suma_matrices.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_BFkeDJbGA-",
        "outputId": "bc1bfaed-c930-4ccc-d93f-ddff941552fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o suma_matrices suma_matrices.cu\n",
        "!ls"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t1destencil_no_shared.cu  suma_matrices\n",
            "1destencil_exercise.cu\tsuma0.cu\t\t suma_matrices.cu\n",
            "1destencilexercise.cu\tsuma1.cu\t\t suma_vectores\n",
            "1destencil_no_shared\tsuma2.cu\t\t suma_vectores.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSrWk79DbKwu",
        "outputId": "5f07ece2-96d2-4e06-9916-201f47b5ed87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./suma_matrices"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==779== NVPROF is profiling process 779, command: ./suma_matrices\n",
            "Suma de 1024x1024 elementos\n",
            "Número de errores: 0\n",
            "Max error: 0\n",
            "==779== Profiling application: ./suma_matrices\n",
            "==779== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:  100.00%  3.4779ms         1  3.4779ms  3.4779ms  3.4779ms  add(int, float**, float**)\n",
            "      API calls:   92.01%  209.96ms      2050  102.42us  3.2620us  201.04ms  cudaMallocManaged\n",
            "                    6.19%  14.119ms      2050  6.8870us  5.3490us  182.23us  cudaFree\n",
            "                    1.53%  3.4906ms         1  3.4906ms  3.4906ms  3.4906ms  cudaDeviceSynchronize\n",
            "                    0.18%  401.77us         1  401.77us  401.77us  401.77us  cuDeviceTotalMem\n",
            "                    0.06%  139.98us        97  1.4430us     142ns  58.352us  cuDeviceGetAttribute\n",
            "                    0.02%  38.820us         1  38.820us  38.820us  38.820us  cudaLaunchKernel\n",
            "                    0.01%  29.478us         1  29.478us  29.478us  29.478us  cuDeviceGetName\n",
            "                    0.00%  2.8260us         1  2.8260us  2.8260us  2.8260us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8500us         3     616ns     185ns  1.2710us  cuDeviceGetCount\n",
            "                    0.00%  1.0870us         2     543ns     254ns     833ns  cuDeviceGet\n",
            "                    0.00%     264ns         1     264ns     264ns     264ns  cuDeviceGetUuid\n",
            "\n",
            "==779== Unified Memory profiling result:\n",
            "Device \"Tesla T4 (0)\"\n",
            "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
            "     635  13.001KB  4.0000KB  468.00KB  8.062500MB  2.285312ms  Host To Device\n",
            "      75  110.08KB  4.0000KB  0.9922MB  8.062500MB  775.2320us  Device To Host\n",
            "       6         -         -         -           -  5.888064ms  Gpu page fault groups\n",
            "Total CPU Page faults: 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UikvJUnCb4MR",
        "outputId": "3bb1b845-8c17-424a-bb0b-816259f86dce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencil_no_shared.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        1000\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)*64\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "\tprintf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "\t  cudaGetErrorString(error), \\\n",
        "\t  __FILE__, __LINE__); \\\n",
        "\texit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\t// __shared__ int temp[/* WHAT SIZE? */];\n",
        "\t// int gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\t// int lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "\t// // Read input elements into shared memory\n",
        "\t// temp[lindex] = in[gindex];\n",
        "\t// if (threadIdx.x < RADIUS){\n",
        "\t// \ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t// \ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t// }\n",
        "\n",
        "\t// // Apply the stencil\n",
        "\t// int result = 0;\n",
        "\t// for (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t// \tresult += temp[lindex + offset];\n",
        "\n",
        "\t// // Store the result\n",
        "\t// out[gindex-RADIUS] = result;\n",
        "\n",
        "\tint gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t\tresult += in[gindex + offset];\n",
        "\n",
        "\t// Store the result\n",
        "\tout[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "\th_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "\tif (h_out[i] != 7){\n",
        "\t  printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "\t  break;\n",
        "\t}\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "\tprintf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 1destencil_no_shared.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aevsjMC2YD-G",
        "outputId": "7ba808c4-20cd-492d-b937-9aa5dcb494b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o 1destencil_no_shared 1destencil_no_shared.cu\n",
        "!ls"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t    1destencil_no_shared     suma_matrices\n",
            "1destencil_exercise.cu\t    1destencil_no_shared.cu  suma_matrices.cu\n",
            "1destencilexercise.cu\t    suma0.cu\t\t     suma_vectores\n",
            "1destencilexercise_sync     suma1.cu\t\t     suma_vectores.cu\n",
            "1destencilexercise_sync.cu  suma2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzrmGWyEcLyt",
        "outputId": "40612f16-04d6-4532-92f7-d338421c0922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./1destencil_no_shared"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1714== NVPROF is profiling process 1714, command: ./1destencil_no_shared\n",
            "Element h_out[0] == 2001 != 7\n",
            "==1714== Profiling application: ./1destencil_no_shared\n",
            "==1714== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   85.34%  3.3697ms         1  3.3697ms  3.3697ms  3.3697ms  stencil_1d(int*, int*)\n",
            "                   10.43%  411.68us         1  411.68us  411.68us  411.68us  [CUDA memcpy HtoD]\n",
            "                    4.24%  167.36us         1  167.36us  167.36us  167.36us  [CUDA memcpy DtoH]\n",
            "      API calls:   96.73%  189.55ms         2  94.773ms  91.718us  189.45ms  cudaMalloc\n",
            "                    2.81%  5.5005ms         2  2.7502ms  579.30us  4.9212ms  cudaMemcpy\n",
            "                    0.18%  347.55us         1  347.55us  347.55us  347.55us  cuDeviceTotalMem\n",
            "                    0.17%  327.91us         2  163.95us  121.87us  206.03us  cudaFree\n",
            "                    0.08%  158.02us        97  1.6290us     155ns  65.974us  cuDeviceGetAttribute\n",
            "                    0.02%  32.918us         1  32.918us  32.918us  32.918us  cudaLaunchKernel\n",
            "                    0.01%  28.370us         1  28.370us  28.370us  28.370us  cuDeviceGetName\n",
            "                    0.00%  3.7760us         1  3.7760us  3.7760us  3.7760us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8010us         3     600ns     206ns  1.1990us  cuDeviceGetCount\n",
            "                    0.00%     981ns         2     490ns     244ns     737ns  cuDeviceGet\n",
            "                    0.00%     279ns         1     279ns     279ns     279ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7psX5x9VbjhW",
        "outputId": "968673cb-6c34-42de-ad0d-14970e3d35f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencilexercise.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        1000\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)*64\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "\tprintf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "\t  cudaGetErrorString(error), \\\n",
        "\t  __FILE__, __LINE__); \\\n",
        "\texit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\t__shared__ int temp[BLOCK_SIZE+2*RADIUS];\n",
        "\tint gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\tint lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "\t// Read input elements into shared memory\n",
        "\ttemp[lindex] = in[gindex];\n",
        "\tif (threadIdx.x < RADIUS){\n",
        "\t\ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t\ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t}\n",
        "\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t\tresult += temp[lindex + offset];\n",
        "\n",
        "\t// Store the result\n",
        "\tout[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "\th_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "\tif (h_out[i] != 201){\n",
        "\t  printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "\t  break;\n",
        "\t}\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "\tprintf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 1destencilexercise.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp9KyB_Kcam1",
        "outputId": "f7e0a627-13cc-4b4d-bcb6-985ea758ab57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o 1destencilexercise 1destencilexercise.cu\n",
        "!ls"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t    1destencil_no_shared     suma_matrices\n",
            "1destencil_exercise.cu\t    1destencil_no_shared.cu  suma_matrices.cu\n",
            "1destencilexercise.cu\t    suma0.cu\t\t     suma_vectores\n",
            "1destencilexercise_sync     suma1.cu\t\t     suma_vectores.cu\n",
            "1destencilexercise_sync.cu  suma2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gevCbnSeLxT",
        "outputId": "1001ba81-7976-4ac7-f6f5-19d126e9d348",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./1destencilexercise"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1661== NVPROF is profiling process 1661, command: ./1destencilexercise\n",
            "Element h_out[0] == 768 != 7\n",
            "==1661== Profiling application: ./1destencilexercise\n",
            "==1661== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   85.77%  2.8661ms         1  2.8661ms  2.8661ms  2.8661ms  stencil_1d(int*, int*)\n",
            "                    9.32%  311.45us         1  311.45us  311.45us  311.45us  [CUDA memcpy HtoD]\n",
            "                    4.91%  164.06us         1  164.06us  164.06us  164.06us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.01%  191.49ms         2  95.747ms  90.045us  191.40ms  cudaMalloc\n",
            "                    2.47%  4.8726ms         2  2.4363ms  486.92us  4.3857ms  cudaMemcpy\n",
            "                    0.22%  430.32us         1  430.32us  430.32us  430.32us  cuDeviceTotalMem\n",
            "                    0.16%  324.95us         2  162.48us  117.42us  207.53us  cudaFree\n",
            "                    0.09%  170.96us        97  1.7620us     152ns  79.351us  cuDeviceGetAttribute\n",
            "                    0.03%  62.198us         1  62.198us  62.198us  62.198us  cudaLaunchKernel\n",
            "                    0.02%  30.767us         1  30.767us  30.767us  30.767us  cuDeviceGetName\n",
            "                    0.00%  3.4080us         1  3.4080us  3.4080us  3.4080us  cuDeviceGetPCIBusId\n",
            "                    0.00%  1.8870us         3     629ns     170ns  1.2070us  cuDeviceGetCount\n",
            "                    0.00%  1.1990us         2     599ns     328ns     871ns  cuDeviceGet\n",
            "                    0.00%     288ns         1     288ns     288ns     288ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ycPFIYseTa9",
        "outputId": "cebe39cd-ccde-4f59-b1c3-941552db4f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile 1destencilexercise_sync.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "#define RADIUS        1000\n",
        "#define BLOCK_SIZE    256\n",
        "#define NUM_ELEMENTS  (4096*2)*64\n",
        "\n",
        "// CUDA API error checking macro\n",
        "#define cudaCheck(error) \\\n",
        "  if (error != cudaSuccess) { \\\n",
        "\tprintf(\"Fatal error: %s at %s:%d\\n\", \\\n",
        "\t  cudaGetErrorString(error), \\\n",
        "\t  __FILE__, __LINE__); \\\n",
        "\texit(1); \\\n",
        "  }\n",
        "\n",
        "__global__ void stencil_1d(int *in, int *out){\n",
        "\t__shared__ int temp[BLOCK_SIZE+2*RADIUS];\n",
        "\tint gindex = threadIdx.x + (blockIdx.x * blockDim.x) + RADIUS;\n",
        "\tint lindex = threadIdx.x + RADIUS;\n",
        "\n",
        "\t// Read input elements into shared memory\n",
        "\ttemp[lindex] = in[gindex];\n",
        "\tif (threadIdx.x < RADIUS){\n",
        "\t\ttemp[lindex - RADIUS] = in[gindex - RADIUS];\n",
        "\t\ttemp[lindex + BLOCK_SIZE] = in[gindex + BLOCK_SIZE];\n",
        "\t}\n",
        "\n",
        "\t__syncthreads();\n",
        "\n",
        "\t// Apply the stencil\n",
        "\tint result = 0;\n",
        "\tfor (int offset = -RADIUS ; offset <= RADIUS ; offset++)\n",
        "\t\tresult += temp[lindex + offset];\n",
        "\n",
        "\t// Store the result\n",
        "\tout[gindex-RADIUS] = result;\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  unsigned int i;\n",
        "  int h_in[NUM_ELEMENTS + 2 * RADIUS], h_out[NUM_ELEMENTS];\n",
        "  int *d_in, *d_out;\n",
        "\n",
        "  // Initialize host data\n",
        "  for( i = 0; i < (NUM_ELEMENTS + 2*RADIUS); ++i )\n",
        "\th_in[i] = 1; // With a value of 1 and RADIUS of 3, all output values should be 7\n",
        "\n",
        "  // Allocate space on the device\n",
        "  cudaCheck( cudaMalloc( &d_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int)) );\n",
        "  cudaCheck( cudaMalloc( &d_out, NUM_ELEMENTS * sizeof(int)) );\n",
        "\n",
        "  // Copy input data to device\n",
        "  cudaCheck( cudaMemcpy( d_in, h_in, (NUM_ELEMENTS + 2*RADIUS) * sizeof(int), cudaMemcpyHostToDevice) );\n",
        "\n",
        "  stencil_1d<<< (NUM_ELEMENTS + BLOCK_SIZE - 1)/BLOCK_SIZE, BLOCK_SIZE >>> (d_in, d_out);\n",
        "\n",
        "  cudaCheck( cudaMemcpy( h_out, d_out, NUM_ELEMENTS * sizeof(int), cudaMemcpyDeviceToHost) );\n",
        "\n",
        "  // Verify every out value is 7\n",
        "  for( i = 0; i < NUM_ELEMENTS; ++i )\n",
        "\tif (h_out[i] != 201){\n",
        "\t  printf(\"Element h_out[%d] == %d != 7\\n\", i, h_out[i]);\n",
        "\t  break;\n",
        "\t}\n",
        "\n",
        "  if (i == NUM_ELEMENTS)\n",
        "\tprintf(\"SUCCESS!\\n\");\n",
        "\n",
        "  // Free out memory\n",
        "  cudaFree(d_in);\n",
        "  cudaFree(d_out);\n",
        "\n",
        "  return 0;\n",
        "}\n",
        "\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting 1destencilexercise_sync.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piDN4NjVgS_B",
        "outputId": "f3024cc1-8566-4e41-add4-eb4d9434e706",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc -o 1destencilexercise_sync 1destencilexercise_sync.cu\n",
        "!ls"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1destencilexercise\t    1destencil_no_shared     suma_matrices\n",
            "1destencil_exercise.cu\t    1destencil_no_shared.cu  suma_matrices.cu\n",
            "1destencilexercise.cu\t    suma0.cu\t\t     suma_vectores\n",
            "1destencilexercise_sync     suma1.cu\t\t     suma_vectores.cu\n",
            "1destencilexercise_sync.cu  suma2.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_k-II-ggVU3",
        "outputId": "8ac10ae6-6af2-42a3-f1d1-d4f3320ad094",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvprof ./1destencilexercise_sync"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==1773== NVPROF is profiling process 1773, command: ./1destencilexercise_sync\n",
            "Element h_out[0] == 768 != 7\n",
            "==1773== Profiling application: ./1destencilexercise_sync\n",
            "==1773== Profiling result:\n",
            "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
            " GPU activities:   85.85%  2.8666ms         1  2.8666ms  2.8666ms  2.8666ms  stencil_1d(int*, int*)\n",
            "                    9.24%  308.54us         1  308.54us  308.54us  308.54us  [CUDA memcpy HtoD]\n",
            "                    4.91%  163.84us         1  163.84us  163.84us  163.84us  [CUDA memcpy DtoH]\n",
            "      API calls:   97.58%  235.93ms         2  117.97ms  95.804us  235.84ms  cudaMalloc\n",
            "                    2.02%  4.8947ms         2  2.4474ms  489.00us  4.4057ms  cudaMemcpy\n",
            "                    0.15%  358.06us         1  358.06us  358.06us  358.06us  cuDeviceTotalMem\n",
            "                    0.14%  348.66us         2  174.33us  143.96us  204.71us  cudaFree\n",
            "                    0.07%  171.59us        97  1.7680us     148ns  76.515us  cuDeviceGetAttribute\n",
            "                    0.01%  33.547us         1  33.547us  33.547us  33.547us  cudaLaunchKernel\n",
            "                    0.01%  26.626us         1  26.626us  26.626us  26.626us  cuDeviceGetName\n",
            "                    0.00%  3.3940us         1  3.3940us  3.3940us  3.3940us  cuDeviceGetPCIBusId\n",
            "                    0.00%  2.0830us         3     694ns     272ns  1.3260us  cuDeviceGetCount\n",
            "                    0.00%  1.6220us         2     811ns     290ns  1.3320us  cuDeviceGet\n",
            "                    0.00%     306ns         1     306ns     306ns     306ns  cuDeviceGetUuid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb25-XWsgbh9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}